\section {Methodology - Abhilash}

\subsection{Glushko 6 Questions - Abhilash and Chris}

\subsection{Data Dictionary and Metadata - Chris}

\subsection{Ontology - Chris} 

\subsection{Data Model - Abhilash} 

\subsection{Technical Implementation of the website}

The website is a custom front-end mostly using web standards and open-source software and libraries. The assumption is that it will mainly be used in a desktop environment by the users to explore on larger screens so the website is not fully responsive and thus not mobile-optimized. 

\subsubsection{Front-end frameworks}
The web application is created with the open-source front-end framework Svelte \footnote{https://svelte.dev} and UI framework SvelteKit which allows the application to be built-in interface components, each chart is rendered separately making it more efficient to add functionality (e.g. add datasets, render different chart types) in the future but also makes the website performant when more data and charts are added. Svelte can be downloaded as a module (package) from NPM \footnote{https://www.npmjs.com} and uses the JavaScript back-end run-time Node.js \footnote{https://nodejs.org/}. For the charts the JavaScript charting library Chart.js \footnote{https://www.chartjs.org} is integrated into the components which allows charts to be rendered in HTML5 Canvas without much configuration. 

\subsubsection{Dataloading}
The processed and transformed dataset was used as a primary data source of which subsets of the dataset in \textit{.csv} format, roughly one per year chart and section, are converted to \textit{.json}. These data files are loaded on page load of the browser. For this prototype, no back-end was set up and no database queries are being made. Any filter options and updating of the charts are more custom, it uses JavaScript utility functions to allow the data to be pre-processed and have only the data change. For the map page, an additional Chart.js Geo Plugin is used to render the Chloropleth map. It uses a TopoJSON \footnote{https://github.com/topojson/topojson}file to render the regions of the World.

\subsection{Machine Learning Model}
\subsubsection{Data-set presentation}
Bellow the surface provides a data-set\cite{DatasetBelow} of all the objects resulting from the excavations. The data is provided in the form of a .csv file, with 139190 rows and 163 columns. Each row corresponds to an object. Describing each object is well outside of the scope of the purposes of this section, however, an explanation of the relevant columns is necessary. \\
The following columns are relevant for the purposes of the ML model: 
\begin{itemize}
    \item vondstnummer - represents a unique inventory number, in the form of a string. Every object has a vondstnummer. Example: "NZC1.00001MTL001".
    \item  object -  a description of the contents of the object. Example: "sieve residue"
    \item  subcategorie - a categorisation of the object material. Example: "metal: copper alloy"
    \item objectdeel - describes the object type morphologically (if it is part of a bigger object, a set, etc). Example: "fragment"
    \item vlak\_min - Describes the minimum depth at which the object might have been found. Example: "-22.0"
    \item vlak\_max - Describes the maximum depth at which the object might have been found. Example: "-22.01"
    \item begin\_dat - The beginning of the interval of the estimated year of the object. Example: "1675.0"
    \item eind\_dat - End of the interval of the estimated year of the object. Example: "1725.0"
    \item niveau1 - The category in which the object is placed. Example:  "Communication \& Exchange"
\end{itemize}
For the columns \textit{object, subcategorie, objectdeel, vlak\_min, vlak\_max, begin\_dat, eind\_dat,  niveau1} there are rows in the dataset in which one or more of these columns are blank.  \\
The column \textit{niveau1} can take the value of one of 12 pre-determined categories, as well as the value "Not classified". As previously mentioned, there are rows where this column is blank. 
\subsubsection{Objectives}
Our objective is to create a machine-learning model that will complete the missing data for the "niveau1" column. This means that our model will predict a value in the niveau1 column, for the rows where currently that column is blank or has the value "Not classified". The prediction will be based on the values in the \textit{object, subcategorie, objectdeel, vlak\_min, vlak\_max, begin\_dat, eind\_dat,  niveau1} columns, which will act like input to the machine-learning model. 
\subsubsection{Deliverables}
In order to achieve our objectives, the following files are delivered: 
\begin{itemize}
    \item process\_dataset.py - a simple python script that takes the original 163 column .csv files and consolidates it into another .csv files that only contains the columns of interest. The name of this .csv file is "selected\_dataset.csv" 
    \item machine\_learning.py - this python script is the backbone of the machine-learning process. It is a more-complex script that does the following steps: 
        \begin{itemize}
            \item Loads the "selected\_dataset.csv" dataset
            \item Preprocess the data (completes the values with 0 or placeholders here they are blank", etc)
            \item Converts text stings to vectors
            \item Splits the data into unlabeled and labelled data based on the values in the "niveau1" column
            \item Splits the labelled data using a training, testing, and validation split
            \item Builds the ML model
            \item Compiles the model
            \item Trains the model
            \item Tests the model
            \item Predicts the values of niveau1 for the unlabelled data
            \item Saves the updated dataset into a file named predicted\_dataset.csv
        \end{itemize}
    \item predicted\_dataset.csv - a file containing the dataset in selected\_dataset.csv, but with the column selected\_dataset.csv fully completed. 
\end{itemize}
\subsubsection{Model description}
