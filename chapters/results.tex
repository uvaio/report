\section{Results}

\subsection{Website}

The original website has a lot of individual objects and detailed metadata about physical properties. The aim of the website was mainly to \textit{summarise} the collection to allow the before-mentioned users to explore the broad dataset and find interesting patterns. Then the user would be able to  \textit{create a subset} of the dataset based on physical properties and categories by further filtering the dataset. The design is based on the branding of the original Below the surface project and follows standard information architecture (e.g. primary navigation, form filters) and visual design principles.

\subsubsection{Overview summary page}
On loading of the website, the user is greeted with a 'summary' overview page (shown in Figure \ref{fig:summary}) with introductory text and three visualizations that display; \textit{time of origin} in horizontally stacked bar charts, \textit{functional properties} in a polar chart and \textit{material usage} in a doughnut chart. The page has a primary top navigation to 'smooth-scroll' to each section and a 'create a subset' floating action button to navigate to the collection detail page.

\subsubsection{Collection detail subset}
Based on the categories of the summary page a user can create a subset of the collection on the 'create a subset' detail page (shown in Figure \ref{fig:subset}). Above the fold, the user has the option to use the same \textit{category filters} from the summary page. Then a user additionally has the option to click on the filter dropdown to expose more form filter options using a checkbox with more granular options such as location found, size and dimensions and material technique. A 'download subset' button allows the user to download the generated subset in .csv format.

\subsection{Machine Learning Model}
Following training the neural network over 50 epochs, the accuracy of the neural network was tested. An accuracy of approximately 75\% was obtained over the test data, which the neural network has never seen before. The accuracy is considered satisfactory for the given application. Furthermore, the neural network was used to classify the remaining unlabelled data, the results being deemed satisfactory.

\subsection{Dataset}

\subsubsection{Initial Dataset}
The initial dataset as provided in Below the surface website was structured as a flat model with each row representing an individual archaeological object. This flat structure included many columns, each corresponding to specific attributes associated with the objects. These attributes are stored in a wide range of material categories, such as ceramics, building materials, fauna, glass, and more. While the flat model provided an accessible format for data entry, it led to redundant storage of certain information, challenging in visualization, particularly common attributes that applied to all finds.

\subsubsection{Data Transformation and Normalization}
The dataset was provided in a flat model, which presented certain challenges in terms of data redundancy and efficient visualization. To address these issues and enhance the integrity of the data, a normalization process was done to fit the data into the relational model as described in the Data Model section.

\subsection{Ontology and Data Dictionary}
The initial data dictionary provided by the Below the surface website contained limited descriptions of the metadata. This posed a challenge to understanding the information in the flat-file dataset.  Further work was performed to enrich the information so that it would be useful.  For example, adding information about which geographic locations referred to which project code.

The ontology was created from scratch as none was supplied with the original website. Over 35 classes were created which covered aspects of the find-number, location, and various physical characteristics of the objects. It is now possible to determine which project code refers to which physical location. All of the finds were imported as individuals and assigned as a type of 'vondstnummer' or 'find'. To import the find numbers into a turtle format correctly, the full stops needed to be removed from the find numbers. Having the full stop included resulted in the turtle file becoming unreadable. The code to assign the find number to the correct class in the ontology is provided.
